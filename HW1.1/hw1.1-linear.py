#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Mon Sep  5 18:28:32 2021

@author: sunhaoxian
"""
#import all the packages needed
import json
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from scipy.optimize import minimize
import pandas as pd

# A class used to generate display the original data set for further use
class Data:

    #initializer
    def __init__(self, name):
        self.name = name
        self.out = {}
    
    #read in file
    def write_json(self):
        with open(self.name, "w") as write_file:
            json.dump(self.out, write_file)
            
    #generate the age, weight and is_adult data
    def partition(self):
        self.out["xlabel"]="age"
        self.out["ylabel"]="weight"
        N=250; xmin=3; xmax=100; SF=0.12
        self.x = np.linspace(xmin, xmax, N)
        y = 181.0/(1+np.exp(-(self.x-13)/4))+20
        noise = SF*(max(y)-min(y))*np.random.uniform(-1,1,size=len(self.x))
        self.yn = y + noise
        self.out["x"] = self.x.tolist()
        self.out["y"] = self.yn.tolist()
        A_or_C = [] 
        for i in range(0,len(self.x)):
            if(self.x[i]<18):
                A_or_C.append(0)
            else:
                A_or_C.append(1)
        self.out["is_adult"] = A_or_C
        
    #display the original dataset
    def plot(self):
        fig, ax = plt.subplots()
        ax.plot(self.x, self.yn, 'o', label = "weight")
        ax.legend()
        FS=18   #FONT SIZE
        plt.xlabel(self.out["xlabel"], fontsize=FS)
        plt.ylabel(self.out["ylabel"], fontsize=FS)
        plt.title("Original Dataset")
        plt.show()
        
        
#class to conduct linear regression on dataset
class Linear:
    w_data = Data("weight.json")
    w_data.write_json()
    w_data.partition()
    iterations=[]
    loss_train=[]
    loss_val=[]
    ite = 0
    
    #initialize x and y and their means and standard deviations respectively
    #in this case, x is age and y is weight (< 18 years old)
    def __init__(self):
        df = pd.DataFrame(list(zip(self.w_data.out["x"], self.w_data.out["y"])),
               columns =['Age', 'Weight'])
        select_df = df.loc[df['Age'] < 18]
        self.x = select_df['Age']
        self.y = select_df['Weight']
        self.y_mean = np.mean(self.y)
        self.y_std = np.std(self.y)
        self.x_mean = np.mean(self.x)
        self.x_std = np.std(self.x)
        
    #split the dataset into 2 groups, 20% test and 80% train
    def split(self):
        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(self.x, self.y, test_size=0.20)
        
    #normalize the inputs and outputs using standard scaler
    def normalize(self):
        self.x_nor_train = [(val - self.x_mean) / self.x_std for val in self.x_train]
        self.y_nor_train = [(val - self.y_mean) / self.y_std for val in self.y_train]
        self.x_nor_test = [(val - self.x_mean) / self.x_std for val in self.x_test]
        self.y_nor_test = [(val - self.y_mean) / self.y_std for val in self.y_test]
        self.x_nor = [(val - self.x_mean) / self.x_std for val in self.x]
        
    #This is the function to generate the predicted y with inputs x and p
    def modelFunc(self, x, p):
        return [p[0] * i + p[1] for i in x]
    
    #The loss function to record and return the mean squard error between the true values 
    #and predicted values. Further, by applying minimize to this function, we can find
    #the best p that can minize the mean square error and store it as our linear 
    #regression function. 
    def loss(self, p):
        y_pred = self.modelFunc(self.x_nor_train, p)
        train_loss = mean_squared_error(self.y_nor_train, y_pred)
        self.loss_train.append(train_loss)
        y_test_pred = self.modelFunc(self.x_nor_test, p)
        test_loss = mean_squared_error(self.y_nor_test, y_test_pred)
        self.loss_val.append(test_loss)
        self.ite += 1
        self.iterations.append(self.ite)
        return train_loss
    
    #unnormalize the predicted y generated by the modelFunc above, to compare these
    #results with the true values
    def unnormalize(self, y_pred):
        return [self.y_std * i + self.y_mean for i in y_pred]
    
    #display the loss change as the number of iterations increases
    def displayLoss(self):
        fig, ax = plt.subplots()
        ax.plot(self.iterations, self.loss_train, '--', label='train loss')
        ax.plot(self.iterations, self.loss_val, '-', label='test loss')
        ax.legend()
        FS=18   #FONT SIZE
        plt.xlabel('Number of Iterations', fontsize=FS)
        plt.ylabel('Loss', fontsize=FS)
        plt.title("Loss vs Iterations")
        plt.show()
        
    
#Main Function
if __name__ == "__main__":
    #generate and plot the original datasets
    data = Data("weight.json")
    data.write_json()
    data.partition()
    data.plot()
    
    #initialize the linear model
    linear = Linear()
    linear.split()
    linear.normalize()
    NFIT = 2
    #RANDOM INITIAL GUESS FOR FITTING PARAMETERS
    po=np.random.uniform(0.5,1.,size=NFIT)
    #obtain the best coefficients
    res = minimize(linear.loss, po, method='Nelder-Mead', tol=1e-15)
    popt=res.x
    print("OPTIMAL PARAM:",popt)
    #display the loss change
    linear.displayLoss()
    
    #generate the model
    x = linear.x_nor
    y_pred_norm = linear.modelFunc(x, popt)
    y_pred = linear.unnormalize(y_pred_norm)
    
    #display the results
    fig, ax = plt.subplots()
    ax.plot(data.x, data.yn, 'o', label = "original")
    ax.plot(linear.x_train, linear.y_train, 'g*', label = "train set")
    ax.plot(linear.x_test, linear.y_test, 'rx', label = "test set")
    ax.plot(linear.x, y_pred, 'k', label='linear regression')
    ax.legend()
    FS=18   #FONT SIZE
    plt.xlabel("age", fontsize=FS)
    plt.ylabel("weight", fontsize=FS)
    plt.title("Linear Regression")
    plt.show()

        
        
        
        
        