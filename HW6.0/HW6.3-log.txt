_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 32, 32, 3)]       0         
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 32, 32, 32)        896       
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 16, 16, 32)        0         
_________________________________________________________________
conv2d_13 (Conv2D)           (None, 16, 16, 16)        4624      
_________________________________________________________________
max_pooling2d_6 (MaxPooling2 (None, 8, 8, 16)          0         
_________________________________________________________________
conv2d_14 (Conv2D)           (None, 8, 8, 16)          2320      
_________________________________________________________________
up_sampling2d_5 (UpSampling2 (None, 16, 16, 16)        0         
_________________________________________________________________
conv2d_15 (Conv2D)           (None, 16, 16, 32)        4640      
_________________________________________________________________
up_sampling2d_6 (UpSampling2 (None, 32, 32, 32)        0         
_________________________________________________________________
conv2d_16 (Conv2D)           (None, 32, 32, 3)         867       
=================================================================
Total params: 13,347
Trainable params: 13,347
Non-trainable params: 0
_________________________________________________________________



{'loss': [0.6903917193412781,
  0.6806621551513672,
  0.6609859466552734,
  0.6366798281669617,
  0.6203816533088684,
  0.6114677786827087,
  0.6059516072273254,
  0.6007513403892517,
  0.5966233015060425,
  0.593226969242096,
  0.5905285477638245,
  0.5884454846382141,
  0.5868600606918335,
  0.5852775573730469,
  0.5840592980384827,
  0.5831505656242371,
  0.582138180732727,
  0.5810837149620056,
  0.5802962183952332,
  0.5795767307281494,
  0.5789123177528381,
  0.5783377885818481,
  0.5778301358222961,
  0.5773344039916992,
  0.5767552852630615,
  0.5763865113258362,
  0.5765105485916138,
  0.5760073065757751,
  0.5755079388618469,
  0.5751650333404541,
  0.5747153759002686,
  0.574297308921814,
  0.5738804340362549,
  0.5734602808952332,
  0.5731886625289917,
  0.5728014707565308,
  0.5724928975105286,
  0.572181224822998,
  0.5719175338745117,
  0.5717819333076477,
  0.5714019536972046,
  0.5721673369407654,
  0.5714308023452759,
  0.570855975151062,
  0.570610761642456,
  0.570396900177002,
  0.5701321363449097,
  0.569836437702179,
  0.5696461200714111,
  0.5693987607955933,
  0.569286048412323,
  0.5689723491668701,
  0.568766713142395,
  0.5689147114753723,
  0.5685064792633057,
  0.5684078931808472,
  0.5685675740242004,
  0.5683760046958923,
  0.5680897831916809,
  0.5682109594345093,
  0.5679552555084229,
  0.5675830245018005,
  0.567470908164978,
  0.5673047304153442,
  0.5671066641807556,
  0.5669613480567932,
  0.5667971968650818,
  0.5666953921318054,
  0.5666306614875793,
  0.5665327906608582,
  0.566435694694519,
  0.5663619041442871,
  0.5663871169090271,
  0.5667744874954224,
  0.5665041208267212,
  0.5662990808486938,
  0.5661590695381165,
  0.5660650730133057,
  0.5659303665161133,
  0.5657204389572144,
  0.5655965805053711,
  0.5655475854873657,
  0.5654664039611816,
  0.5654560923576355,
  0.5653529763221741,
  0.5651928782463074,
  0.5652512907981873,
  0.5651249289512634,
  0.5653897523880005,
  0.565139651298523,
  0.5649762749671936,
  0.5649380683898926,
  0.5648629665374756,
  0.5647581815719604,
  0.5648038983345032,
  0.5645273923873901,
  0.5645057559013367,
  0.5645915865898132,
  0.5644800066947937,
  0.5643975734710693],
 'val_loss': [0.6851656436920166,
  0.6705995202064514,
  0.644705057144165,
  0.6257268786430359,
  0.6156281232833862,
  0.610106348991394,
  0.604738712310791,
  0.5995171666145325,
  0.5959484577178955,
  0.5935496687889099,
  0.5912451148033142,
  0.5900231003761292,
  0.5879200100898743,
  0.5870543122291565,
  0.5863067507743835,
  0.5850900411605835,
  0.5838345885276794,
  0.5831851959228516,
  0.5825077891349792,
  0.5816938281059265,
  0.5810566544532776,
  0.5805129408836365,
  0.5800683498382568,
  0.5795634984970093,
  0.5791602730751038,
  0.5786762237548828,
  0.5790053009986877,
  0.5779517889022827,
  0.5776851773262024,
  0.5778800249099731,
  0.576945960521698,
  0.5766645669937134,
  0.5762813687324524,
  0.5759479999542236,
  0.5757040977478027,
  0.5752661824226379,
  0.5749807357788086,
  0.5747219324111938,
  0.5745334625244141,
  0.5743253827095032,
  0.5741375684738159,
  0.5741609334945679,
  0.5738138556480408,
  0.5732423067092896,
  0.5732249021530151,
  0.573064923286438,
  0.5727072358131409,
  0.5724450945854187,
  0.5722974538803101,
  0.5721616744995117,
  0.5717900395393372,
  0.5716403126716614,
  0.5713608264923096,
  0.5715508460998535,
  0.5714696645736694,
  0.5717849731445312,
  0.5712599158287048,
  0.5710031986236572,
  0.5717026591300964,
  0.5709436535835266,
  0.5701680779457092,
  0.5702921152114868,
  0.5701960921287537,
  0.5698342323303223,
  0.5697129964828491,
  0.5695978403091431,
  0.5694835782051086,
  0.5693866014480591,
  0.5693762898445129,
  0.5693122148513794,
  0.5691736340522766,
  0.5689899325370789,
  0.5697265267372131,
  0.5691066980361938,
  0.5689550638198853,
  0.5690257549285889,
  0.5690199136734009,
  0.5689117312431335,
  0.5685474276542664,
  0.5683972835540771,
  0.5683102607727051,
  0.5682838559150696,
  0.568332314491272,
  0.5681246519088745,
  0.5679630041122437,
  0.5679010152816772,
  0.5679765343666077,
  0.5682205557823181,
  0.5676858425140381,
  0.5678172707557678,
  0.5676989555358887,
  0.5678651332855225,
  0.5676433444023132,
  0.5676960945129395,
  0.567310631275177,
  0.5672466158866882,
  0.5673751831054688,
  0.5672134160995483,
  0.5671979188919067,
  0.567478597164154]}


The fraction of times anomalies in mnist dataset is: 0.0
The fraction of times anomalies in fashion mnist dataset is: 0.0